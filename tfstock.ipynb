{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pymysql\n",
    "\n",
    "input_vec_size = lstm_size = 7\n",
    "time_step_size = 60\n",
    "label_size = 3\n",
    "evaluate_size = 2\n",
    "lstm_depth = 4\n",
    "\n",
    "total_size = 60000\n",
    "batch_size = 15000\n",
    "test_size = total_size - batch_size\n",
    "conn = pymysql.connect(host='192.168.1.210',\n",
    "                                          user='root',\n",
    "                                          password='1234',\n",
    "                                          db='data',\n",
    "                                          charset='utf8mb4')\n",
    "\n",
    "\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(code, X, W, B, lstm_size):\n",
    "    XT = tf.transpose(X, [1, 0, 2]) \n",
    "    XR = tf.reshape(XT, [-1, lstm_size])\n",
    "    X_split = tf.split(0, time_step_size, XR)\n",
    "    with tf.variable_scope(code, reuse=False):\n",
    "        cell = tf.nn.rnn_cell.GRUCell(lstm_size)\n",
    "        cell = tf.nn.rnn_cell.DropoutWrapper(cell = cell, output_keep_prob = 0.5)\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell([cell] * lstm_depth, state_is_tuple = True)\n",
    "\n",
    "    # Get lstm cell output, time_step_size (60) arrays with lstm_size output: (batch_size, lstm_size)\n",
    "    outputs, _states = tf.nn.rnn(cell, X_split, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation\n",
    "    # Get the last output\n",
    "    return tf.matmul(outputs[-1], W) + B, cell.state_size # State size to initialize the stat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_codedates(code):\n",
    "    code_dates = list()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT date FROM data.daily_stock WHERE code = %s ORDER BY date\", (code))\n",
    "    dates = cursor.fetchall()\n",
    "    for date in dates:\n",
    "        code_dates.append((code[0], date[0]))    \n",
    "    return code_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_series_datas(conn, code_dates):\n",
    "    X = list()\n",
    "    Y = list()\n",
    "\n",
    "    for code_date in code_dates:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT open, high, low, close, volume, hold_foreign, st_purchase_inst FROM data.daily_stock WHERE code = %s AND date >= %s ORDER BY date LIMIT %s\",\n",
    "                       (code_date[0], code_date[1], time_step_size + evaluate_size))\n",
    "        items = cursor.fetchall()        \n",
    "        X.append(np.array(items))\n",
    "        if len(items) < evaluate_size :\n",
    "            break\n",
    "        st_purchase_inst = items[-(evaluate_size + 1)][6] ##\n",
    "        if st_purchase_inst == 0:\n",
    "            continue\n",
    "        for i in range(evaluate_size, len(items) - evaluate_size):\n",
    "            eval_inst = items[i][6]\n",
    "            eval_bef = items[evaluate_size-i][6]\n",
    "            if eval_bef < eval_inst:\n",
    "                eval_bef = eval_inst           \n",
    "        \n",
    "        if (eval_bef - st_purchase_inst) / st_purchase_inst < -0.02: #percent ? cnt ? \n",
    "            Y.append((0., 0., 1.))\n",
    "        elif (eval_bef - st_purchase_inst) / st_purchase_inst > 0.04:\n",
    "            Y.append((1., 0., 0.))\n",
    "        else:\n",
    "            Y.append((0., 1., 0.))\n",
    "\n",
    "\n",
    "    arrX = np.array(X)\n",
    "    norX = (arrX - np.mean(arrX, axis = 0)) / np.std(arrX, axis = 0)\n",
    "    norY = np.array(Y)\n",
    "    return norX, norY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_datas(code_dates):    \n",
    "    np.random.seed()\n",
    "    np.random.shuffle(code_dates)\n",
    "\n",
    "    trX = list()\n",
    "    trY = list()\n",
    "    trX, trY = read_series_datas(conn, code_dates)\n",
    "    teX, teY = read_series_datas(conn, code_dates)\n",
    "\n",
    "    return trX, trY, teX, teY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_codes():\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT DISTINCT code FROM data.daily_stock LIMIT 10\")\n",
    "    codes = cursor.fetchall()\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 1 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f36a352681c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtest_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0morg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mteX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mteY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 1 with size 0"
     ]
    }
   ],
   "source": [
    "\n",
    "for code in get_codes():\n",
    "    tf.reset_default_graph()\n",
    "    code_dates = get_codedates(code[0])\n",
    "    trX, trY, teX, teY = read_datas(code_dates)\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, time_step_size, input_vec_size])\n",
    "    Y = tf.placeholder(tf.float32, [None, label_size])\n",
    "\n",
    "    # get lstm_size and output 3 labels\n",
    "    W = init_weights([lstm_size, label_size])\n",
    "    B = init_weights([label_size])\n",
    "\n",
    "    py_x, state_size = model(code[0], X, W, B, lstm_size)\n",
    "\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(py_x, Y)\n",
    "    cost = tf.reduce_mean(loss)\n",
    "    train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "    predict_op = tf.argmax(py_x, 1)\n",
    "\n",
    "    # Launch the graph in a session\n",
    "    with tf.Session() as sess:\n",
    "        # you need to initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        for i in range(100):\n",
    "            for start, end in zip(range(0, len(trX), batch_size), range(batch_size, len(trX)+1, batch_size)):\n",
    "                sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    "\n",
    "            test_indices = np.arange(len(teX))\n",
    "            \n",
    "            org = teY[test_indices]\n",
    "            res = sess.run(predict_op, feed_dict={X: teX[test_indices], Y: teY[test_indices]})\n",
    "\n",
    "            print(code[0], i, np.mean(np.argmax(org, axis=1) == res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
